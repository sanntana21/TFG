{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNupwBMwVuMKUsWpyYh9Lza",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanntana21/TFG/blob/first_model_implementation/entrenamiento_individual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WYnHR4AeH9d",
        "outputId": "3ec7a6ab-d559-4dda-cc9d-294a4f41e037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#  We start by getting access to the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "from fastai.data.core import DataLoaders\n",
        "from fastai.learner import Learner\n",
        "from fastai.metrics import mse\n",
        "from fastai.losses import MSELossFlat\n",
        "from fastai.callback.all import *\n",
        "from fastai.data.transforms import *\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import random as random\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "IRtTEUJJeZPF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FUNCIONES AUXILIARES**"
      ],
      "metadata": {
        "id": "46dNy0Oqe4uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_preds(model, input_data):\n",
        "  \"\"\"\n",
        "  Uses model to make predictions on input_data.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model: trained model \n",
        "  input_data: windowed input data (same kind of data model was trained on)\n",
        "\n",
        "  Returns model predictions on input_data.\n",
        "  \"\"\"\n",
        "  forecast = model.predict(input_data)\n",
        "  return tf.squeeze(forecast) # return 1D array of predictions\n",
        "\n",
        "def plot_predictions_vs_real(predictions, reals):\n",
        "    df = pd.DataFrame()\n",
        "    number_of_points = len(predictions)\n",
        "    df[\"hour\"] = range(0,number_of_points)\n",
        "    df[\"participant\"] = \"prediction\"\n",
        "    df[\"value\"] = predictions\n",
        "    for i in range(0,number_of_points):\n",
        "      df.loc[number_of_points+i] = [i,\"real\",reals[i]]\n",
        "\n",
        "    print(df)\n",
        "\n",
        "    plt.figure(1)\n",
        "    fig = px.line(df, x = \"hour\", y = \"value\" , title = \"predicitons vs reals\" , color = \"participant\")\n",
        "    fig.update_xaxes(\n",
        "          rangeslider_visible = True,\n",
        "          rangeselector = dict(\n",
        "              buttons = list([\n",
        "                  dict(count=1,label=\"1y\",step=\"year\",stepmode=\"backward\"),\n",
        "                  dict(count=2,label=\"2y\",step=\"year\",stepmode=\"backward\"),\n",
        "                  dict(count=3,label=\"3y\",step=\"year\",stepmode=\"backward\"),\n",
        "                  dict(step=\"all\")\n",
        "              ])\n",
        "          )\n",
        "\n",
        "      )\n",
        "    fig.show()\n",
        "\n",
        "def set_output_precision(decimals):\n",
        "  \"\"\"\n",
        "  format the output of the all the data structures\n",
        "  with an specific number of decimals\n",
        "  \"\"\"\n",
        "  np.set_printoptions(precision=decimals)\n",
        "  into='{'+':.{}f'.format(decimals)+'}'\n",
        "  pd.options.display.float_format = into.format\n",
        "\n",
        "  pass\n",
        "\n",
        "set_output_precision(6)"
      ],
      "metadata": {
        "id": "utEpd3OPevgH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Procesamiento de los datos**"
      ],
      "metadata": {
        "id": "UiolFpfzfHe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First we read datasets into pandasDataFrame\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/TFG/Resources/METS_in_minutes.csv\",sep=\",\",dtype={\"METS_by_hour_for_all_population\":\"float32\"})\n",
        "\n",
        "\n",
        "print(\"Desviación de METS:\" , df[\"METS\"].std())\n",
        "print('\\033[1m' + \"SET OF VALUES\\n\" + '\\033[0m')\n",
        "print(df.head())\n",
        "\n",
        "total_nan_values = df.apply(lambda x: x.isna().sum())[\"METS\"]\n",
        "\n",
        "print('\\033[1m' + \"\\nValores NULOS: \"  + '\\033[0m' + str(total_nan_values) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXGOLtqTfNU0",
        "outputId": "6b14c227-d819-4152-8ea7-67fe30ffe445"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Desviación de METS: 0.4516855486903255\n",
            "\u001b[1mSET OF VALUES\n",
            "\u001b[0m\n",
            "  participant            timestamp  minute     METS\n",
            "0       A3FNz  2021-11-16 00:00:00       0 0.000000\n",
            "1       A3FNz  2021-11-16 00:01:00       1 0.000000\n",
            "2       A3FNz  2021-11-16 00:02:00       2 0.000000\n",
            "3       A3FNz  2021-11-16 00:03:00       3 0.000000\n",
            "4       A3FNz  2021-11-16 00:04:00       4 0.000000\n",
            "\u001b[1m\n",
            "Valores NULOS: \u001b[0m0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate trainable sets for the LSTM\n",
        "\n",
        "def create_minutes_to_minutes_forecasting_sets(values):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(0, values[\"minute\"].max() - 1439*2,1):\n",
        "        first_minute_in_window = i\n",
        "        last_minute_in_window = i + 1440\n",
        "        last_minute_in_prediction = last_minute_in_window + 1440\n",
        "        X.append([j for j in values.loc[(values[\"minute\"] >= first_minute_in_window) & (values[\"minute\"] < last_minute_in_window)][\"METS\"]])\n",
        "        y.append([j for j in values.loc[(values[\"minute\"] >= last_minute_in_window) & (values[\"minute\"] < last_minute_in_prediction)][\"METS\"]])\n",
        "    return X,y\n",
        "\n",
        "\n",
        "def create_minutes_to_hours_forecasting_sets(y_in_minutes):\n",
        "    y = []\n",
        "    for window_of_values in y_in_minutes:\n",
        "        y.append([ sum(window_of_values[first_minute_of_the_hour:first_minute_of_the_hour+60]) for first_minute_of_the_hour in range(0,1440-59,60)])\n",
        "    return y\n",
        "\n",
        "\n",
        "def create_minutes_to_day_forecasting_sets(y_in_minutes):\n",
        "    y = []\n",
        "    for window_of_values in y_in_minutes:\n",
        "        y.append([sum(window_of_values)])\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "n6dMp0wuiKjB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SETS GENERATION**"
      ],
      "metadata": {
        "id": "LANGB3J69B7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataX = []\n",
        "dataY_minute = []\n",
        "dataY_hour = []\n",
        "dataY_day = []\n",
        "\n",
        "participants =  df['participant'].unique()\n",
        "for participant in participants[:]:\n",
        "  pX,pY = create_minutes_to_minutes_forecasting_sets(df.loc[(df[\"participant\"] == participant)])\n",
        "  dataX.append(pX)\n",
        "  dataY_minute.append(pY)\n",
        "  dataY_hour.append(create_minutes_to_hours_forecasting_sets(pY))\n",
        "  dataY_day.append(create_minutes_to_day_forecasting_sets(pY))\n",
        "\n",
        "dataX = np.array(dataX)\n",
        "for dataY in [ np.array(dataY_minute), np.array(dataY_hour), np.array(dataY_day)]:\n",
        "  # This 24 correspond to the hours of the first day which didn't have 1440 previous minutes\n",
        "  print('\\033[1m' + \"\\t SHAPES\" + '\\033[0m')\n",
        "  print(dataX.shape)\n",
        "  print(dataY.shape)\n",
        "  # set the precision of the array to 15 decimal places\n",
        "  print('\\033[1m'+\"\\t First Element\"+'\\033[0m')\n",
        "  print(dataX[0])\n",
        "  print(dataY[0])\n",
        "\n",
        "  print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.\")"
      ],
      "metadata": {
        "id": "dtWPuw8N8vTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "file_path = '/content/drive/MyDrive/TFG/Resources/'\n",
        "documents = ['minuteX','minuteY','hourX','hourY']\n",
        "data_to_save = [dataX,dataY_minute,dataY_hour,dataY_day]\n",
        "# Save the list using pickle\n",
        "for i in range(0,4,1):\n",
        "  with open(file_path+documents[i]+\".pkl\", 'wb') as file:\n",
        "      pickle.dump(data_to_save[i], file)"
      ],
      "metadata": {
        "id": "c-6e0RaXGxfk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}