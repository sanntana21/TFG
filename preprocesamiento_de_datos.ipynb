{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "mount_file_id": "1xVYDA08BoQTB9IidzLB3dlPjvHtaE9v5",
   "authorship_tag": "ABX9TyPuXl+xlwSO2x8O57oHlhl4",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sanntana21/TFG/blob/first_model_implementation/preprocesamiento_de_datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ],
   "metadata": {
    "id": "IRtTEUJJeZPF"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "DATA_SET_AGRUPADO = dict() \n",
    "DATA_SET_INDIVIDUAL = dict()\n",
    "DATA_SET_MATRICIAL = dict()\n",
    "\n",
    "DATA_SET_AGRUPADO[\"generar\"] = False\n",
    "DATA_SET_AGRUPADO[\"cargar\"] = False\n",
    "DATA_SET_AGRUPADO[\"pintar\"] = False\n",
    "\n",
    "DATA_SET_INDIVIDUAL[\"generar\"] = False\n",
    "DATA_SET_INDIVIDUAL[\"pintar\"] = False\n",
    "DATA_SET_INDIVIDUAL[\"cargar\"] = False\n",
    "DATA_SET_MATRICIAL[\"generar\"] = False\n",
    "DATA_SET_MATRICIAL[\"pintar\"] = False\n",
    "\n",
    "initial = True\n",
    "MINUTES_PER_DAY = 1440\n",
    "HOURS_PER_DAY = 24\n",
    "DAY = 1\n",
    "STARTED_MINUTE = 1440\n",
    "MINUTES_IN_THE_STUDY = 41760\n",
    "LOCAL = True\n",
    "GENERAR_DATA_SET_LIMITADO = True"
   ],
   "metadata": {
    "id": "Kh4qWiQIDg4H"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **FUNCIONES AUXILIARES**"
   ],
   "metadata": {
    "id": "46dNy0Oqe4uJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def make_preds(model, input_data):\n",
    "  \"\"\"\n",
    "  Uses model to make predictions on input_data.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  model: trained model \n",
    "  input_data: windowed input data (same kind of data model was trained on)\n",
    "\n",
    "  Returns model predictions on input_data.\n",
    "  \"\"\"\n",
    "  forecast = model.predict(input_data)\n",
    "  return tf.squeeze(forecast) # return 1D array of predictions\n",
    "\n",
    "def plot_predictions_vs_real(predictions, reals):\n",
    "    df = pd.DataFrame()\n",
    "    number_of_points = len(predictions)\n",
    "    df[\"hour\"] = range(0,number_of_points)\n",
    "    df[\"participant\"] = \"prediction\"\n",
    "    df[\"value\"] = predictions\n",
    "    for i in range(0,number_of_points):\n",
    "      df.loc[number_of_points+i] = [i,\"real\",reals[i]]\n",
    "\n",
    "    print(df)\n",
    "\n",
    "    plt.figure(1)\n",
    "    fig = px.line(df, x = \"hour\", y = \"value\" , title = \"predicitons vs reals\" , color = \"participant\")\n",
    "    fig.update_xaxes(\n",
    "          rangeslider_visible = True,\n",
    "          rangeselector = dict(\n",
    "              buttons = list([\n",
    "                  dict(count=1,label=\"1y\",step=\"year\",stepmode=\"backward\"),\n",
    "                  dict(count=2,label=\"2y\",step=\"year\",stepmode=\"backward\"),\n",
    "                  dict(count=3,label=\"3y\",step=\"year\",stepmode=\"backward\"),\n",
    "                  dict(step=\"all\")\n",
    "              ])\n",
    "          )\n",
    "\n",
    "      )\n",
    "    fig.show()\n",
    "\n",
    "def set_output_precision(decimals):\n",
    "  \"\"\"\n",
    "  format the output of the all the data structures\n",
    "  with an specific number of decimals\n",
    "  \"\"\"\n",
    "  np.set_printoptions(precision=decimals)\n",
    "  into='{'+':.{}f'.format(decimals)+'}'\n",
    "  pd.options.display.float_format = into.format\n",
    "\n",
    "  pass\n",
    "\n",
    "set_output_precision(6)\n",
    "\n",
    "\n",
    "def plot_ts(df,dfx=\"Minute\",dfy=\"METS\",_title=\"DF minute x Mets\"):\n",
    "  if not isinstance(df,pd.DataFrame):\n",
    "    df = pd.DataFrame({'METS': df, 'Minute': range(len(df))})\n",
    "\n",
    "  plt.figure()\n",
    "  fig = px.line(df, x = dfx, y = dfy , title = _title)\n",
    "  fig.update_xaxes(\n",
    "      rangeslider_visible = True,\n",
    "      rangeselector = dict(\n",
    "          buttons = list([\n",
    "              dict(count=1,label=\"1y\",step=\"year\",stepmode=\"backward\"),\n",
    "              dict(count=2,label=\"2y\",step=\"year\",stepmode=\"backward\"),\n",
    "              dict(count=3,label=\"3y\",step=\"year\",stepmode=\"backward\"),\n",
    "              dict(step=\"all\")\n",
    "          ])\n",
    "      )\n",
    "\n",
    "  )\n",
    "  fig.show()"
   ],
   "metadata": {
    "id": "utEpd3OPevgH"
   },
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 53\u001B[0m\n\u001B[0;32m     49\u001B[0m   pd\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mdisplay\u001B[38;5;241m.\u001B[39mfloat_format \u001B[38;5;241m=\u001B[39m into\u001B[38;5;241m.\u001B[39mformat\n\u001B[0;32m     51\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m---> 53\u001B[0m \u001B[43mset_output_precision\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot_ts\u001B[39m(df,dfx\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMinute\u001B[39m\u001B[38;5;124m\"\u001B[39m,dfy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMETS\u001B[39m\u001B[38;5;124m\"\u001B[39m,_title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDF minute x Mets\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(df,pd\u001B[38;5;241m.\u001B[39mDataFrame):\n",
      "Cell \u001B[1;32mIn[3], line 47\u001B[0m, in \u001B[0;36mset_output_precision\u001B[1;34m(decimals)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_output_precision\u001B[39m(decimals):\n\u001B[0;32m     43\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;124;03m  format the output of the all the data structures\u001B[39;00m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;124;03m  with an specific number of decimals\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m   \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39mset_printoptions(precision\u001B[38;5;241m=\u001B[39mdecimals)\n\u001B[0;32m     48\u001B[0m   into\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:.\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(decimals)\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     49\u001B[0m   pd\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mdisplay\u001B[38;5;241m.\u001B[39mfloat_format \u001B[38;5;241m=\u001B[39m into\u001B[38;5;241m.\u001B[39mformat\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Procesamiento de los datos**"
   ],
   "metadata": {
    "id": "UiolFpfzfHe1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#First we read datasets into pandasDataFrame\n",
    "if LOCAL:\n",
    "    path = \"Resources/METS_in_minutes.csv\"\n",
    "else:\n",
    "    #  We start by getting access to the drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    path = \"/content/drive/MyDrive/TFG/Resources/METS_in_minutes.csv\"\n",
    "\n",
    "df = pd.read_csv(path,sep=\",\",dtype={\"METS\":\"float32\"})\n",
    "\n",
    "print(\"Desviación de METS:\" , df[\"METS\"].std())\n",
    "print('\\033[1m' + \"SET OF VALUES\\n\" + '\\033[0m')\n",
    "print(df.head())\n",
    "\n",
    "total_nan_values = df.apply(lambda x: x.isna().sum())[\"METS\"]\n",
    "\n",
    "print('\\033[1m' + \"\\nValores NULOS: \"  + '\\033[0m' + str(total_nan_values) )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXGOLtqTfNU0",
    "outputId": "43bebcac-ccee-4295-dbeb-9c039affbd7c"
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desviación de METS: 0.5084145\n",
      "\u001B[1mSET OF VALUES\n",
      "\u001B[0m\n",
      "  participant            timestamp  minute     METS\n",
      "0       A3FNz  2021-11-16 00:00:00       0 0.000000\n",
      "1       A3FNz  2021-11-16 00:01:00       1 0.000000\n",
      "2       A3FNz  2021-11-16 00:02:00       2 0.000000\n",
      "3       A3FNz  2021-11-16 00:03:00       3 0.000000\n",
      "4       A3FNz  2021-11-16 00:04:00       4 0.000000\n",
      "\u001B[1m\n",
      "Valores NULOS: \u001B[0m0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "errores = df.loc[(df[\"METS\"] < 1) & (df[\"minute\"] > 1440)]\n",
    "STARTED_MINUTE = int(errores[\"minute\"].max())\n",
    "COMBINATIONS = (MINUTES_IN_THE_STUDY - MINUTES_PER_DAY*2 - (STARTED_MINUTE-1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Generate trainable sets for the LSTM\n",
    "\n",
    "def create_minutes_to_minutes_forecasting_sets(values,started_minute = 0):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(started_minute, values[\"minute\"].max() - 1439*2,1):\n",
    "        first_minute_in_window = i\n",
    "        last_minute_in_window = i + 1440\n",
    "        last_minute_in_prediction = last_minute_in_window + 1440\n",
    "        X.append([j for j in values.loc[(values[\"minute\"] >= first_minute_in_window) & (values[\"minute\"] < last_minute_in_window)][\"METS\"]])\n",
    "        y.append([j for j in values.loc[(values[\"minute\"] >= last_minute_in_window) & (values[\"minute\"] < last_minute_in_prediction)][\"METS\"]])\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def create_minutes_to_hours_forecasting_sets(y_in_minutes,started_minute = 0):\n",
    "    y = []\n",
    "    for window_of_values in y_in_minutes:\n",
    "        y.append([ sum(window_of_values[first_minute_of_the_hour:first_minute_of_the_hour+60]) for first_minute_of_the_hour in range(started_minute,1440-59,60)])\n",
    "    return y\n",
    "\n",
    "\n",
    "def create_minutes_to_day_forecasting_sets(y_in_minutes):\n",
    "    y = []\n",
    "    for window_of_values in y_in_minutes:\n",
    "        y.append([sum(window_of_values)])\n",
    "    return y\n"
   ],
   "metadata": {
    "id": "n6dMp0wuiKjB"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **SETS GENERATION**"
   ],
   "metadata": {
    "id": "LANGB3J69B7A"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GENERATE AGGREGATED DATA\n"
   ],
   "metadata": {
    "id": "2eiAbaCI1U85"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# DATA_SET_AGRUPADO[\"generar\"] = False\n",
    "def generate_aggregated_data(df):\n",
    "  dataX = []\n",
    "  dataY_minute = []\n",
    "  dataY_hour = []\n",
    "  dataY_day = []\n",
    "\n",
    "  # Paso 1: Agrupa por tiempo y suma los valores de los participantes\n",
    "  df_aggregated_by_minute = df.groupby('minute').sum()\n",
    "\n",
    "  # Paso 2: Restablece el índice para convertir 'tiempo' en una columna nuevamente\n",
    "  df_aggregated_by_minute = df_aggregated_by_minute.reset_index()\n",
    "\n",
    "  pX,pY = create_minutes_to_minutes_forecasting_sets(df_aggregated_by_minute,started_minute=STARTED_MINUTE)\n",
    "  dataX.append(pX)\n",
    "  dataY_minute.append(pY)\n",
    "  dataY_hour.append(create_minutes_to_hours_forecasting_sets(pY))\n",
    "  dataY_day.append(create_minutes_to_day_forecasting_sets(pY))\n",
    "  return dataX,dataY_minute,dataY_hour,dataY_day\n",
    "\n",
    "def load_aggregated_data():\n",
    "  file_path = '/content/drive/MyDrive/TFG/Resources/Agregado/'\n",
    "  documents = ['minuteX','minuteY','hourY','dayY']\n",
    "  data_to_load = []\n",
    "  # Save the list using pickle\n",
    "  for i in range(0,4,1):\n",
    "    with open(file_path+documents[i]+\".pkl\", 'rb') as file:\n",
    "        data_to_load.append(pickle.load(file))\n",
    "\n",
    "  return data_to_load[0],data_to_load[1],data_to_load[2],data_to_load[3]\n",
    "\n",
    "dataX = []\n",
    "dataY_minute = []\n",
    "dataY_hour = []\n",
    "dataY_day = []\n",
    "\n",
    "\n",
    "if DATA_SET_AGRUPADO[\"generar\"] == True:\n",
    "  dataX,dataY_minute,dataY_hour,dataY_day = generate_aggregated_data(df)\n",
    "  file_path = '/content/drive/MyDrive/TFG/Resources/Agregado/'\n",
    "  documents = ['minuteX','minuteY','hourY','dayY']\n",
    "  data_to_save = [dataX,dataY_minute,dataY_hour,dataY_day]\n",
    "  # Save the list using pickle\n",
    "  for i in range(0,4,1):\n",
    "    with open(file_path+documents[i]+\".pkl\", 'wb') as file:\n",
    "        pickle.dump(data_to_save[i], file)\n",
    "elif DATA_SET_AGRUPADO[\"cargar\"] == True:\n",
    "  dataX,dataY_minute,dataY_hour,dataY_day = load_aggregated_data()\n",
    "\n",
    "dataX = np.array(dataX)\n",
    "dataY_minute = np.array(dataY_minute)\n",
    "dataY_hour = np.array(dataY_hour)\n",
    "dataY_day = np.array(dataY_day)"
   ],
   "metadata": {
    "id": "dtWPuw8N8vTr"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if DATA_SET_AGRUPADO[\"pintar\"] == True:\n",
    "  print(dataX.shape)\n",
    "  print(dataY_minute.shape)\n",
    "  print(dataY_hour.shape)\n",
    "  print(dataY_day.shape)\n",
    "  plot_ts(dataX[0][0],_title=\"Serie temporal agregada en minutos del día 1\")\n",
    "  plot_ts(dataY_minute[0][1440],_title=\"Predicción de la serie temporal agregada en minutos del día 1, es decir el día 2\")\n",
    "  plot_ts(dataY_hour[0][14400],_title=\"Predicción de la serie temporal agregada en horas del día 1, es decir el día 2\")\n",
    "  print('\\033[1m' + \"Valor de METS en días para la predicción del día 1, es decir dia 2 \"+'\\033[0m',dataY_day[0][2880])"
   ],
   "metadata": {
    "id": "rSySj2AR5kM6"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## INDIVIDUAL"
   ],
   "metadata": {
    "id": "McFlFTcGGKvv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "if DATA_SET_INDIVIDUAL[\"generar\"] == True:\n",
    "  dataX= np.full((len(df[\"participant\"].unique()),COMBINATIONS,MINUTES_PER_DAY),0.0,dtype=np.float32)\n",
    "  dataY_minute = np.full((len(df[\"participant\"].unique()),COMBINATIONS,MINUTES_PER_DAY),0.0,dtype=np.float32)\n",
    "  dataY_hour = np.full((len(df[\"participant\"].unique()),COMBINATIONS,HOURS_PER_DAY),0.0,dtype=np.float32)\n",
    "  dataY_day = np.full((len(df[\"participant\"].unique()),COMBINATIONS,DAY),0.0,dtype=np.float32)\n",
    "  index = 0\n",
    "  for participant in df[\"participant\"].unique():\n",
    "    px_minute,py_minute = create_minutes_to_minutes_forecasting_sets(df.loc[df[\"participant\"] == participant],started_minute=STARTED_MINUTE)\n",
    "    dataX[index] = px_minute\n",
    "    dataY_minute[index] = py_minute\n",
    "    del px_minute\n",
    "    dataY_hour[index] = create_minutes_to_hours_forecasting_sets(py_minute)\n",
    "    dataY_day[index] = create_minutes_to_day_forecasting_sets(py_minute)\n",
    "    del py_minute\n",
    "    index += 1\n"
   ],
   "metadata": {
    "id": "VdniHc2DWz5t"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "if DATA_SET_INDIVIDUAL[\"generar\"]:\n",
    "    if LOCAL:\n",
    "        file_path = 'Resources/Individual/'\n",
    "    else:\n",
    "        file_path = '/content/drive/MyDrive/TFG/Resources/Individual/'\n",
    "    documents = ['minuteX','minuteY','hourY','dayY']\n",
    "    data_to_save = [dataX,dataY_minute,dataY_hour,dataY_day]\n",
    "    # Save the list using pickle\n",
    "    for i in range(0,4,1):\n",
    "        file = file_path+documents[i]+\".pkl.gz\"\n",
    "        pickle.dump(data_to_save[i], gzip.open(file, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "if GENERAR_DATA_SET_LIMITADO:\n",
    "    if not DATA_SET_INDIVIDUAL[\"generar\"]:\n",
    "        PATH = \"Resources/Individual/\"\n",
    "        documents = ['minuteY','hourY','dayY']\n",
    "        # with open(PATH+\"minuteX\"+\".pkl\", 'rb') as file:\n",
    "        #     dataX = np.array(pickle.load(file),np.float32)\n",
    "        file = PATH+\"minuteX.pkl.gz\"\n",
    "        dataX = np.array(pickle.load(gzip.open(file, 'rb')),np.float32)\n",
    "\n",
    "        file = PATH+documents[0]+\".pkl.gz\"\n",
    "        dataY_minute = np.array(pickle.load(gzip.open(file, 'rb')),np.float32)\n",
    "\n",
    "        file = PATH+documents[1]+\".pkl.gz\"\n",
    "        dataY_hour = np.array(pickle.load(gzip.open(file, 'rb')),np.float32)\n",
    "\n",
    "        file = PATH+documents[2]+\".pkl.gz\"\n",
    "        dataY_day = np.array(pickle.load(gzip.open(file, 'rb')),np.float32)\n",
    "\n",
    "    # Calcular la variabilidad de cada elemento en X\n",
    "    variability = np.std(dataX, axis=(1, 2))  # Calcular la desviación estándar\n",
    "\n",
    "    # Obtener los índices de los 25 elementos con mayor variabilidad\n",
    "    top_indices = np.argsort(variability)[-25:]\n",
    "\n",
    "    # Extraer los mismos elementos de X y Y utilizando los índices\n",
    "    selected_dataX = dataX[top_indices, :, :]\n",
    "    selected_dataY_minute = dataY_minute[top_indices, :, :]\n",
    "    selected_dataY_hour = dataY_hour[top_indices, :, :]\n",
    "    selected_dataY_day = dataY_day[top_indices, :, :]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "    if GENERAR_DATA_SET_LIMITADO and DATA_SET_INDIVIDUAL[\"generar\"] and DATA_SET_INDIVIDUAL[\"cargar\"]:\n",
    "\n",
    "        if LOCAL:\n",
    "          file_path = 'Resources/Individual/LowData/'\n",
    "        else:\n",
    "          file_path = '/content/drive/MyDrive/TFG/Resources/Individual/LowData/'\n",
    "\n",
    "        documents = ['minuteX','minuteY','hourY','dayY']\n",
    "        data_to_save = [selected_dataX,selected_dataY_minute,selected_dataY_hour,selected_dataY_day]\n",
    "        # Save the list using pickle\n",
    "        for i in range(0,4,1):\n",
    "            file = file_path+documents[i]+\".pkl.gz\"\n",
    "            pickle.dump(data_to_save[i], gzip.open(file, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "if GENERAR_DATA_SET_LIMITADO:\n",
    "        if LOCAL:\n",
    "          file_path = 'Resources/Agregado/LowData/'\n",
    "        else:\n",
    "          file_path = '/content/drive/MyDrive/TFG/Resources/Agregado/LowData/'\n",
    "\n",
    "        documents = ['minuteX','minuteY','hourY','dayY']\n",
    "        data_to_save = [np.sum(selected_dataX,axis=0),np.sum(selected_dataY_minute,axis=0),np.sum(selected_dataY_hour,axis=0),np.sum(selected_dataY_day,axis=0)]\n",
    "        # Save the list using pickle\n",
    "        for i in range(0,4,1):\n",
    "            file = file_path+documents[i]+\".pkl.gz\"\n",
    "            pickle.dump(data_to_save[i], gzip.open(file, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
