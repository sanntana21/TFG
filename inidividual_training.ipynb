{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHYH674PSqkP"
   },
   "source": [
    "# **PREDICCIONES PARA UN SOLO PARTICIPANTE**"
   ],
   "id": "UHYH674PSqkP"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"v.0.0\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "from statistics import mean, median\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sbn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import random as random\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def set_output_precision(decimals):\n",
    "  \"\"\"\n",
    "  format the output of the all the data structures\n",
    "  with an specific number of decimals\n",
    "  \"\"\"\n",
    "  np.set_printoptions(precision=decimals)\n",
    "  into='{'+':.{}f'.format(decimals)+'}'\n",
    "  pd.options.display.float_format = into.format\n",
    "  torch.set_printoptions(precision=decimals)\n",
    "  pass\n",
    "\n",
    "def plot_ts(df,dfx=\"Minute\",dfy=\"METS\",_title=\"DF minute x Mets\"):\n",
    "  if not isinstance(df,pd.DataFrame):\n",
    "    df = pd.DataFrame({'METS': df, 'Minute': range(len(df))})\n",
    "\n",
    "  plt.figure()\n",
    "  fig = px.line(df, x = dfx, y = dfy , title = _title)\n",
    "  fig.update_xaxes(\n",
    "      rangeslider_visible = True,\n",
    "      rangeselector = dict(\n",
    "          buttons = list([\n",
    "              dict(count=1,label=\"1y\",step=\"year\",stepmode=\"backward\"),\n",
    "              dict(count=2,label=\"2y\",step=\"year\",stepmode=\"backward\"),\n",
    "              dict(count=3,label=\"3y\",step=\"year\",stepmode=\"backward\"),\n",
    "              dict(step=\"all\")\n",
    "          ])\n",
    "      )\n",
    "\n",
    "  )\n",
    "  fig.show()\n",
    "\n",
    "def plot_predictions_vs_real(predictions, reals):\n",
    "  df = pd.DataFrame()\n",
    "  number_of_points = len(predictions)\n",
    "  df[\"time\"] = range(0,number_of_points)\n",
    "  df[\"participant\"] = \"prediction\"\n",
    "  df[\"value\"] = predictions\n",
    "  for i in range(0,number_of_points):\n",
    "    df.loc[number_of_points+i] = [i,\"real\",reals[i]]\n",
    "\n",
    "  plt.figure(1)\n",
    "  fig = px.line(df, x = \"time\", y = \"value\" , title = \"predictions vs reals\" , color = \"participant\")\n",
    "  fig.update_xaxes(\n",
    "        rangeslider_visible = True,\n",
    "        rangeselector = dict(\n",
    "            buttons = list([\n",
    "                dict(count=1,label=\"1y\",step=\"year\",stepmode=\"backward\"),\n",
    "                dict(count=2,label=\"2y\",step=\"year\",stepmode=\"backward\"),\n",
    "                dict(count=3,label=\"3y\",step=\"year\",stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    )\n",
    "  fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "INDEXS = [{\"train\":[{\"start\":{\"day\":2,\"hour\":0,\"minute\":0},\n",
    "                     \"end\":{\"day\":20,\"hour\":22,\"minute\":0}}\n",
    "                    ],\n",
    "           \"validation\":[{\"start\":{\"day\":22,\"hour\":0,\"minute\":0},\n",
    "                     \"end\":{\"day\":24,\"hour\":22,\"minute\":0}}\n",
    "                    ],\n",
    "           \"test\":[{\"start\":{\"day\":26,\"hour\":0,\"minute\":0},\n",
    "                     \"end\":{\"day\":27,\"hour\":22,\"minute\":0}}\n",
    "                    ]}\n",
    "          ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "3x-vPqs_LjtB"
   },
   "outputs": [],
   "source": [
    "READ_LOCAL_DATA = True\n",
    "COMPUTED_OPTION = 1\n",
    "TEST_SIZE = 0.2\n",
    "VALIDATION_SIZE = 0.15\n",
    "SAVE_RESULTS = True\n",
    "LOW_DATA = True\n",
    "SPLIT_INTO_TWO_DAYS = True\n",
    "MULTI_STEP_FORECAST = False\n",
    "SPLIT = 0\n",
    "np.random.seed(42)"
   ],
   "id": "3x-vPqs_LjtB"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "2UBiboWvo0TI"
   },
   "outputs": [],
   "source": [
    "if READ_LOCAL_DATA:\n",
    "  PATH = \"Resources/Individual/\"\n",
    "else:\n",
    "    #  We start by getting access to the drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    PATH = \"/content/drive/MyDrive/TFG/Resources/Individual/\"\n",
    "\n",
    "if LOW_DATA:\n",
    "    PATH += \"LowData/\""
   ],
   "id": "2UBiboWvo0TI"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Wx-eUkHY7S6",
    "outputId": "0af8d1fc-e14f-46d4-8db5-8f643d562ff5"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[78], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# with open(PATH+\"minuteX\"+\".pkl\", 'rb') as file:\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#     dataX = np.array(pickle.load(file),np.float32)\u001B[39;00m\n\u001B[0;32m      5\u001B[0m file \u001B[38;5;241m=\u001B[39m PATH\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mminuteX.pkl.gz\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 6\u001B[0m dataX \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[43mpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgzip\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m,np\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m      8\u001B[0m file \u001B[38;5;241m=\u001B[39m PATH\u001B[38;5;241m+\u001B[39mdocuments[COMPUTED_OPTION]\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.pkl.gz\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      9\u001B[0m dataY \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(pickle\u001B[38;5;241m.\u001B[39mload(gzip\u001B[38;5;241m.\u001B[39mopen(file, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m)),np\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\gzip.py:300\u001B[0m, in \u001B[0;36mGzipFile.read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m    298\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01merrno\u001B[39;00m\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(errno\u001B[38;5;241m.\u001B[39mEBADF, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread() on write-only GzipFile object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 300\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_compression.py:68\u001B[0m, in \u001B[0;36mDecompressReader.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreadinto\u001B[39m(\u001B[38;5;28mself\u001B[39m, b):\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b) \u001B[38;5;28;01mas\u001B[39;00m view, view\u001B[38;5;241m.\u001B[39mcast(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m byte_view:\n\u001B[1;32m---> 68\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbyte_view\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m         byte_view[:\u001B[38;5;28mlen\u001B[39m(data)] \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\gzip.py:495\u001B[0m, in \u001B[0;36m_GzipReader.read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;66;03m# Read a chunk of data from the file\u001B[39;00m\n\u001B[0;32m    493\u001B[0m buf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread(io\u001B[38;5;241m.\u001B[39mDEFAULT_BUFFER_SIZE)\n\u001B[1;32m--> 495\u001B[0m uncompress \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_decompressor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecompress\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decompressor\u001B[38;5;241m.\u001B[39munconsumed_tail \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    497\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mprepend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decompressor\u001B[38;5;241m.\u001B[39munconsumed_tail)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "documents = ['minuteY','hourY','dayY']\n",
    "# with open(PATH+\"minuteX\"+\".pkl\", 'rb') as file:\n",
    "#     dataX = np.array(pickle.load(file),np.float32)\n",
    "file = PATH+\"minuteX.pkl.gz\"\n",
    "dataX = np.array(pickle.load(gzip.open(file, 'rb')),np.float32)\n",
    "\n",
    "file = PATH+documents[COMPUTED_OPTION]+\".pkl.gz\"\n",
    "dataY = np.array(pickle.load(gzip.open(file, 'rb')),np.float32)\n"
   ],
   "id": "_Wx-eUkHY7S6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUMBER_OF_PARTICIPANTS = dataX.shape[0]\n",
    "if MULTI_STEP_FORECAST:\n",
    "    PREDICTED_HORIZON = 1\n",
    "    if COMPUTED_OPTION == 0:\n",
    "        dataX_nuevo = dataX\n",
    "        JUMP = 1\n",
    "    elif COMPUTED_OPTION == 1:\n",
    "        JUMP = 60\n",
    "        dataX_nuevo = np.ones(shape=(NUMBER_OF_PARTICIPANTS,dataX.shape[1],24))\n",
    "        for k in range(0,NUMBER_OF_PARTICIPANTS):\n",
    "            for i in range(0,dataX.shape[1]):\n",
    "                for j in range(0,24):\n",
    "                    dataX_nuevo[k,i,j] = np.sum(dataX[k,i,60*j:60*(j+1)])\n",
    "    else:\n",
    "        JUMP = 1440\n",
    "        dataX_nuevo = np.ones(shape=(dataX.shape[0],1))\n",
    "        for k in range(0,NUMBER_OF_PARTICIPANTS):\n",
    "            for i in range(0,dataX.shape[0]):\n",
    "                dataX_nuevo[k,i,:] = np.sum(dataX[k,i,:])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2182a00",
    "outputId": "e280fc1d-d52a-49b3-f3b8-b74ee23fee3f"
   },
   "outputs": [],
   "source": [
    "def change_shape_by_participant(data):\n",
    "    original_shape = data.shape\n",
    "    new_shape = (original_shape[0] * original_shape[1], original_shape[2])\n",
    "    reshaped_array = data.reshape(new_shape)\n",
    "    return reshaped_array"
   ],
   "id": "c2182a00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if MULTI_STEP_FORECAST:\n",
    "    dataX_nuevo = dataX_nuevo.transpose(1,0,2)\n",
    "\n",
    "#We split a test set for testing\n",
    "# train_test_split(dataX, dataY, test_size=TEST_SIZE)\n",
    "\n",
    "def calculate_index(time):\n",
    "  minute_index = time[\"day\"] * 1440 + time[\"hour\"]*60 + time[\"minute\"]\n",
    "  return minute_index\n",
    "\n",
    "def get_split(dataX,dataY,index):\n",
    "  start = calculate_index(index[0][\"start\"])\n",
    "  end = calculate_index(index[0][\"end\"])\n",
    "  X_split = dataX[:,start:end,:]\n",
    "  y_split = dataY[:,start:end,:]\n",
    "  if len(index) > 1:\n",
    "    for i in range(1,index):\n",
    "      start = calculate_index(index[i][\"start\"])\n",
    "      end = calculate_index(index[i][\"end\"])\n",
    "      X_split = np.concatenate(X_split,dataX[:,start:end,:])\n",
    "      y_split = np.concatenate(y_split,dataY[:,start:end,:])\n",
    "  return X_split,y_split\n",
    "\n",
    "def train_test_validation_split(dataX,dataY,indexs):\n",
    "  X_train,y_train = get_split(dataX,dataY,indexs[\"train\"])\n",
    "  X_validation,y_validation = get_split(dataX,dataY,indexs[\"validation\"])\n",
    "  X_test,y_test = get_split(dataX,dataY,indexs[\"test\"])\n",
    "  return X_train,y_train,X_validation,y_validation,X_test,y_test\n",
    "\n",
    "\n",
    "X_train,y_train,X_validation,y_validation,X_test,y_test = train_test_validation_split(dataX,dataY,INDEXS[SPLIT])\n",
    "print(\"Examples for training\\n\",\"X:\",X_train.shape,\"y:\",y_train.shape)\n",
    "print(\"Examples for validation\\n\",\"X:\",X_validation.shape,\"y:\",y_validation.shape)\n",
    "print(\"Examples for test\\n\",\"X:\",X_test.shape,\"y:\",y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train,y_train,X_validation,y_validation,X_test,y_test = [ i.transpose(1,0,2) for i in\n",
    "    [X_train,y_train,X_validation,y_validation,X_test,y_test ]\n",
    "    ]\n",
    "print(\"Examples for training\\n\",\"X:\",X_train.shape,\"y:\",y_train.shape)\n",
    "print(\"Examples for validation\\n\",\"X:\",X_validation.shape,\"y:\",y_validation.shape)\n",
    "print(\"Examples for test\\n\",\"X:\",X_test.shape,\"y:\",y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "X_train,y_train,X_validation,y_validation,X_test,y_test = [ change_shape_by_participant(i) for i in\n",
    "    [X_train,y_train,X_validation,y_validation,X_test,y_test ]\n",
    "    ]\n",
    "print(\"Examples for training\\n\",\"X:\",X_train.shape,\"y:\",y_train.shape)\n",
    "print(\"Examples for validation\\n\",\"X:\",X_validation.shape,\"y:\",y_validation.shape)\n",
    "print(\"Examples for test\\n\",\"X:\",X_test.shape,\"y:\",y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4V6iWDmyjDq",
    "outputId": "2cc487f9-b084-4f58-f441-b83014879d6a"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "# Setup dataset hyperparameters\n",
    "HORIZON = y_test.shape[1]\n",
    "WINDOW_SIZE = X_test.shape[1]\n",
    "\n",
    "# Let's build an LSTM model with the Functional API\n",
    "inputs = layers.Input(shape=(WINDOW_SIZE))\n",
    "x = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(inputs) # expand input dimension to be compatible with LSTM\n",
    "# print(x.shape)\n",
    "# x = layers.LSTM(128, activation=\"relu\", return_sequences=True)(inputs) # this layer will error if the inputs are not the right shape\n",
    "x = layers.LSTM(128,return_sequences=True, activation=\"relu\")(x) # using the tanh loss function results in a massive error\n",
    "# print(x.shape)\n",
    "# Add another optional dense layer (you could add more of these to see if they improve model performance)\n",
    "# x = layers.Dense(32, activation=\"relu\")(x)\n",
    "output = layers.Dense(HORIZON)(x)\n",
    "model_LSTM = tf.keras.Model(inputs=inputs, outputs=output, name=\"model_5_lstm\")\n",
    "\n",
    "model_LSTM.summary()"
   ],
   "id": "C4V6iWDmyjDq"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_LSTM.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "             metrics=[\"mae\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Seems when saving the model several warnings are appearing: https://github.com/tensorflow/tensorflow/issues/47554\n",
    "model_LSTM.fit(X_train,\n",
    "            y_train,\n",
    "            epochs=3,\n",
    "            verbose=1,\n",
    "            batch_size=128,\n",
    "            shuffle=True,\n",
    "            validation_data=(X_validation, y_validation)\n",
    "               )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlZrCDyy0yPY",
    "outputId": "38920a54-fc50-4f9d-803b-c55765235684"
   },
   "outputs": [],
   "source": [
    "def make_preds(model, input_data):\n",
    "  \"\"\"\n",
    "  Uses model to make predictions on input_data.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  model: trained model \n",
    "  input_data: windowed input data (same kind of data model was trained on)\n",
    "\n",
    "  Returns model predictions on input_data.\n",
    "  \"\"\"\n",
    "  forecast = model.predict(input_data)\n",
    "  return tf.squeeze(forecast) # return 1D array of predictions\n",
    "\n",
    "predictions = make_preds(model_LSTM, X_test)"
   ],
   "id": "WlZrCDyy0yPY"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "print(y_test.shape)\n",
    "DATA_BY_PARTICIPANT = int(y_test.shape[0]/25)\n",
    "poblational_prediction = np.ones(shape=(DATA_BY_PARTICIPANT,HORIZON))\n",
    "poblational_y_test = np.ones(shape=(DATA_BY_PARTICIPANT,HORIZON))\n",
    "poblational_X_test = np.ones(shape=(DATA_BY_PARTICIPANT,WINDOW_SIZE))\n",
    "for i in range(0,DATA_BY_PARTICIPANT):\n",
    "    poblational_prediction[i,:] = np.sum(np.array(predictions[i::DATA_BY_PARTICIPANT]),axis=0)\n",
    "    poblational_y_test[i,:] = np.sum(np.array(y_test[i::DATA_BY_PARTICIPANT]),axis=0)\n",
    "    poblational_X_test[i,:] = np.sum(np.array(X_test[i::DATA_BY_PARTICIPANT]),axis=0)\n",
    "print(poblational_prediction.shape)\n",
    "print(poblational_y_test.shape)\n",
    "\n",
    "print('\\033[1m' + \"MSE: \" + str(mean_squared_error(poblational_y_test,poblational_prediction)) + '\\033[0m')\n",
    "print('\\033[1m' + \"MAE: \" + str(mean_absolute_error(poblational_y_test,poblational_prediction)) + '\\033[0m')\n",
    "print(np.mean(poblational_y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SPLIT_INTO_TWO_DAYS = True\n",
    "if not MULTI_STEP_FORECAST:\n",
    "  print(\"Resultados poblacionales cada dos horas\")\n",
    "  print('\\033[1m' + \"MSE: \" + str(mean_squared_error(np.sum(poblational_y_test,axis=1),np.sum(poblational_prediction,axis=1))) + '\\033[0m')\n",
    "  print('\\033[1m' + \"MAE: \" + str(mean_absolute_error(np.sum(poblational_y_test,axis=1),np.sum(poblational_prediction,axis=1))) + '\\033[0m')\n",
    "  print(np.mean(np.sum(poblational_y_test,axis=1)))\n",
    "\n",
    "  list_of_MAE = [  mean_absolute_error(poblational_prediction[i],poblational_y_test[i]) for i in range(0,len(poblational_y_test)) ]\n",
    "  list_of_values = sorted(list_of_MAE)\n",
    "  mean_value = mean(list_of_MAE)\n",
    "  closest_value = min(list_of_MAE, key=lambda x: abs(x - mean_value))\n",
    "  # Crear un array de Ã­ndices\n",
    "  indices = [list_of_MAE.index(list_of_values[-1]),\n",
    "             list_of_MAE.index(closest_value) ,\n",
    "            list_of_MAE.index(list_of_values[0])]\n",
    "  if COMPUTED_OPTION == 0:\n",
    "    for i in indices:\n",
    "      print(list_of_MAE[i])\n",
    "      plot_predictions_vs_real(poblational_prediction[i],poblational_y_test[i])\n",
    "  else:\n",
    "    for i in indices:\n",
    "        print(list_of_MAE[i])\n",
    "        END = 24\n",
    "        STARTED_MINUTE = 0\n",
    "        previous = np.ones(shape=(24))\n",
    "        for j in range(0,24):\n",
    "            previous[j] = np.sum(poblational_X_test[i,:][60*j:60*(j+1)])\n",
    "        predictions_to_plot = np.ones(shape=(END + HORIZON))\n",
    "        predictions_to_plot[0:END] = previous[:]\n",
    "        predictions_to_plot[END:] = poblational_prediction[i,:]\n",
    "        y_test_to_plot = np.ones(shape=(END + HORIZON))\n",
    "        y_test_to_plot[0:END] = previous[:]\n",
    "        y_test_to_plot[END:] = poblational_y_test[i,:]\n",
    "        plot_predictions_vs_real(predictions_to_plot,y_test_to_plot)\n",
    "\n",
    "if SPLIT_INTO_TWO_DAYS:\n",
    "    index = 0\n",
    "    period = poblational_X_test[::120,:]\n",
    "    period_results = make_preds(model_LSTM,period)\n",
    "    period_results_aux = np.array(period_results)\n",
    "    period_results_to_plot = np.array(period_results_aux).reshape(HORIZON*23)\n",
    "    y_test_to_plot = poblational_y_test[::120,:].reshape(HORIZON*23)\n",
    "    plot_predictions_vs_real(predictions=period_results_to_plot,reals=y_test_to_plot)\n",
    "    print('\\033[1m' + \"Predicted: \" + str(np.sum(period_results_to_plot)) + '\\033[0m')\n",
    "    print('\\033[1m' + \"Reals: \" + str(np.sum(y_test_to_plot)) + '\\033[0m')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if SAVE_RESULTS:\n",
    "  if READ_LOCAL_DATA:\n",
    "    file_path = 'Resources/Resultados/Individual/'\n",
    "  else:\n",
    "    file_path = \"/content/drive/MyDrive/TFG/Resources/Resultados/Individual/\"\n",
    "    if LOW_DATA:\n",
    "        file_path += \"LowData/\"\n",
    "\n",
    "    file_path += \"Split\"+str(SPLIT)+\"/\"\n",
    "    documents = ['minuteY','hourY','dayY']\n",
    "    file = file_path+documents[COMPUTED_OPTION]+\"-predictions\"+\".pkl.gz\"\n",
    "    pickle.dump(predictions, gzip.open(file, 'wb'))\n",
    "    file = file_path+documents[COMPUTED_OPTION]+\"-test\"+\".pkl.gz\"\n",
    "    pickle.dump(y_test, gzip.open(file, 'wb'))\n",
    "    file = file_path+documents[COMPUTED_OPTION]+\"-X\"+\".pkl.gz\"\n",
    "    pickle.dump(X_test, gzip.open(file, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
