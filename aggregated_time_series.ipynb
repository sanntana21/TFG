{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sanntana21/TFG/blob/main/aggregated_time_series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHYH674PSqkP"
   },
   "source": [
    "# **PREDICCIONES AGREGADAS**"
   ],
   "id": "UHYH674PSqkP"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v.0.2\n",
      "NECESITO QUE TE GUARDES\n"
     ]
    }
   ],
   "source": [
    "print(\"v.0.1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from statistics import mean, median\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sbn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import random as random\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "import gzip\n",
    "\n",
    "def set_output_precision(decimals):\n",
    "  \"\"\"\n",
    "  format the output of the all the data structures\n",
    "  with an specific number of decimals\n",
    "  \"\"\"\n",
    "  np.set_printoptions(precision=decimals)\n",
    "  into='{'+':.{}f'.format(decimals)+'}'\n",
    "  pd.options.display.float_format = into.format\n",
    "  pass\n",
    "\n",
    "def plot_ts(df,dfx=\"Minute\",dfy=\"METS\",_title=\"DF minute x Mets\"):\n",
    "  if not isinstance(df,pd.DataFrame):\n",
    "    df = pd.DataFrame({'METS': df, 'Minute': range(len(df))})\n",
    "\n",
    "  plt.figure()\n",
    "  fig = px.line(df, x = dfx, y = dfy , title = _title)\n",
    "  fig.update_xaxes(\n",
    "      rangeslider_visible = True,\n",
    "      rangeselector = dict(\n",
    "          buttons = list([\n",
    "              dict(count=1,label=\"1y\",step=\"year\",stepmode=\"backward\"),\n",
    "              dict(count=2,label=\"2y\",step=\"year\",stepmode=\"backward\"),\n",
    "              dict(count=3,label=\"3y\",step=\"year\",stepmode=\"backward\"),\n",
    "              dict(step=\"all\")\n",
    "          ])\n",
    "      )\n",
    "\n",
    "  )\n",
    "  fig.show()\n",
    "\n",
    "def plot_predictions_vs_real(predictions, reals):\n",
    "  df = pd.DataFrame()\n",
    "  number_of_points = len(predictions)\n",
    "  df[\"time\"] = range(0,number_of_points)\n",
    "  df[\"participant\"] = \"prediction\"\n",
    "  df[\"value\"] = predictions\n",
    "  for i in range(0,number_of_points):\n",
    "    df.loc[number_of_points+i] = [i,\"real\",reals[i]]\n",
    "\n",
    "  plt.figure(1)\n",
    "  fig = px.line(df, x = \"time\", y = \"value\" , title = \"predictions vs reals\" , color = \"participant\")\n",
    "  fig.update_xaxes(\n",
    "        rangeslider_visible = True,\n",
    "        rangeselector = dict(\n",
    "            buttons = list([\n",
    "                dict(count=1,label=\"1y\",step=\"year\",stepmode=\"backward\"),\n",
    "                dict(count=2,label=\"2y\",step=\"year\",stepmode=\"backward\"),\n",
    "                dict(count=3,label=\"3y\",step=\"year\",stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    )\n",
    "  fig.show()"
   ],
   "metadata": {
    "id": "kHKU4ikkGZ3d"
   },
   "id": "kHKU4ikkGZ3d"
  },
  {
   "cell_type": "code",
   "source": [
    "INDEXS = [{\"train\":[{\"start\":{\"day\":2,\"hour\":0,\"minute\":0},\n",
    "                     \"end\":{\"day\":21,\"hour\":22,\"minute\":0}}\n",
    "                    ],\n",
    "           \"validation\":[{\"start\":{\"day\":23,\"hour\":0,\"minute\":0},\n",
    "                     \"end\":{\"day\":24,\"hour\":22,\"minute\":0}}\n",
    "                    ],\n",
    "           \"test\":[{\"start\":{\"day\":26,\"hour\":0,\"minute\":0},\n",
    "                     \"end\":{\"day\":27,\"hour\":22,\"minute\":0}}\n",
    "                    ]}\n",
    "          ]"
   ],
   "metadata": {
    "id": "oKqHybXSOubs"
   },
   "id": "oKqHybXSOubs",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3x-vPqs_LjtB"
   },
   "outputs": [],
   "source": [
    "READ_LOCAL_DATA = True\n",
    "COMPUTED_OPTION = 1\n",
    "SAVE_RESULTS = False\n",
    "LOW_DATA = True\n",
    "SPLIT_INTO_TWO_DAYS = False\n",
    "MULTI_STEP_FORECAST = False\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "SPLIT = 0"
   ],
   "id": "3x-vPqs_LjtB"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2UBiboWvo0TI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "32b7f4dc-8cd9-45ec-8b6b-81d9167b6210"
   },
   "outputs": [],
   "source": [
    "if READ_LOCAL_DATA:\n",
    "  PATH = \"Resources/Individual/\"\n",
    "else:\n",
    "    #  We start by getting access to the drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    PATH = \"/content/drive/MyDrive/TFG/Resources/Agregado/\"\n",
    "\n",
    "\n",
    "if LOW_DATA:\n",
    "    PATH += \"LowData/\"\n"
   ],
   "id": "2UBiboWvo0TI"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_Wx-eUkHY7S6"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "documents = ['minuteY','hourY','dayY']\n",
    "# with open(PATH+\"minuteX\"+\".pkl\", 'rb') as file:\n",
    "#     dataX = np.array(pickle.load(file),np.float32)\n",
    "file = PATH+\"minuteX.pkl.gz\"\n",
    "dataX = np.array(pickle.load(gzip.open(file, 'rb')),np.float32)\n",
    "\n",
    "file = PATH+documents[COMPUTED_OPTION]+\".pkl.gz\"\n",
    "dataY = np.array(pickle.load(gzip.open(file, 'rb')),np.float32)\n",
    "\n",
    "dataX = np.sum(dataX,axis=0,keepdims=True)\n",
    "dataY = np.sum(dataY,axis=0,keepdims=True)"
   ],
   "id": "_Wx-eUkHY7S6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if MULTI_STEP_FORECAST:\n",
    "    PREDICTED_HORIZON = 1\n",
    "    if COMPUTED_OPTION == 0:\n",
    "        dataX_nuevo = dataX\n",
    "        JUMP = 1\n",
    "    elif COMPUTED_OPTION == 1:\n",
    "        JUMP = 60\n",
    "        dataX_nuevo = np.ones(shape=(dataX.shape[0],24))\n",
    "        for i in range(0,dataX.shape[0]):\n",
    "            for j in range(0,24):\n",
    "                dataX_nuevo[i,j] = np.sum(dataX[i,60*j:60*(j+1)])\n",
    "    else:\n",
    "        JUMP = 1440\n",
    "        dataX_nuevo = np.ones(shape=(dataX.shape[0],1))\n",
    "        for i in range(0,dataX.shape[0]):\n",
    "            dataX_nuevo[i,:] = np.sum(dataX[i,:])"
   ],
   "metadata": {
    "id": "8uVJlDcYGZ3f"
   },
   "id": "8uVJlDcYGZ3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2182a00",
    "outputId": "2b4549d1-6dc1-44a4-d171-00617aac8d5d"
   },
   "outputs": [],
   "source": [
    "#We split a test set for testing\n",
    "# train_test_split(dataX, dataY, test_size=TEST_SIZE)\n",
    "\n",
    "def calculate_index(time):\n",
    "  minute_index = time[\"day\"] * 1440 + time[\"hour\"]*60 + time[\"minute\"]\n",
    "  return minute_index\n",
    "\n",
    "def get_split(dataX,dataY,index):\n",
    "  start = calculate_index(index[0][\"start\"])\n",
    "  end = calculate_index(index[0][\"end\"])\n",
    "  X_split = dataX[:,start:end,:]\n",
    "  y_split = dataY[:,start:end,:]\n",
    "  if len(index) > 1:\n",
    "    for i in range(1,index):\n",
    "      start = calculate_index(index[i][\"start\"])\n",
    "      end = calculate_index(index[i][\"end\"])\n",
    "      X_split = np.concatenate(X_split,dataX[:,start:end,:])\n",
    "      y_split = np.concatenate(y_split,dataY[:,start:end,:])\n",
    "  return X_split,y_split\n",
    "\n",
    "def train_test_validation_split(dataX,dataY,indexs):\n",
    "  X_train,y_train = get_split(dataX,dataY,indexs[\"train\"])\n",
    "  X_validation,y_validation = get_split(dataX,dataY,indexs[\"validation\"])\n",
    "  X_test,y_test = get_split(dataX,dataY,indexs[\"test\"])\n",
    "  return X_train,y_train,X_validation,y_validation,X_test,y_test\n",
    "\n",
    "\n",
    "X_train,y_train,X_validation,y_validation,X_test,y_test = train_test_validation_split(dataX,dataY,INDEXS[SPLIT])\n",
    "print(\"Examples for training\\n\",\"X:\",X_train.shape,\"y:\",y_train.shape)\n",
    "print(\"Examples for validation\\n\",\"X:\",X_validation.shape,\"y:\",y_validation.shape)\n",
    "print(\"Examples for test\\n\",\"X:\",X_test.shape,\"y:\",y_test.shape)\n"
   ],
   "id": "c2182a00"
  },
  {
   "cell_type": "code",
   "source": [
    "#Quitamos en este caso la primera dimension\n",
    "X_train,y_train,X_validation,y_validation,X_test,y_test = [\n",
    "  np.squeeze(i) for i in [X_train,y_train,X_validation,y_validation,X_test,y_test]\n",
    "]\n",
    "\n",
    "print(\"Examples for training\\n\",\"X:\",X_train.shape,\"y:\",y_train.shape)\n",
    "print(\"Examples for validation\\n\",\"X:\",X_validation.shape,\"y:\",y_validation.shape)\n",
    "print(\"Examples for test\\n\",\"X:\",X_test.shape,\"y:\",y_test.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOOTxfnQKoXG",
    "outputId": "fab50c5e-561f-4a2f-96e7-4bba1960cdb4"
   },
   "id": "jOOTxfnQKoXG",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#**DEFINICION DEL MODELO**"
   ],
   "metadata": {
    "id": "8VAocBLeLDLq"
   },
   "id": "8VAocBLeLDLq",
   "execution_count": 264
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4V6iWDmyjDq",
    "outputId": "694bb9a0-1527-49a6-b521-86b7aca2d128"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "# Setup dataset hyperparameters\n",
    "HORIZON = y_test.shape[1]\n",
    "WINDOW_SIZE = X_test.shape[1]\n",
    "\n",
    "# Let's build an LSTM model with the Functional API\n",
    "inputs = layers.Input(shape=(WINDOW_SIZE))\n",
    "x = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(inputs) # expand input dimension to be compatible with LSTM\n",
    "# print(x.shape)\n",
    "# x = layers.LSTM(128, activation=\"relu\", return_sequences=True)(x) # this layer will error if the inputs are not the right shape\n",
    "x = layers.LSTM(128, activation=\"relu\")(x) # using the tanh loss function results in a massive error\n",
    "# print(x.shape)\n",
    "# Add another optional dense layer (you could add more of these to see if they improve model performance)\n",
    "# x = layers.Dense(32, activation=\"relu\")(x)\n",
    "output = layers.Dense(HORIZON)(x)\n",
    "model_LSTM = tf.keras.Model(inputs=inputs, outputs=output, name=\"model_5_lstm\")\n",
    "\n",
    "model_LSTM.summary()"
   ],
   "id": "C4V6iWDmyjDq"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compile model\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=4,\n",
    "    mode=\"auto\"\n",
    ")\n",
    "model_LSTM.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "             metrics=[\"mae\"])\n"
   ],
   "metadata": {
    "id": "PHgZ-YbNGZ3g"
   },
   "id": "PHgZ-YbNGZ3g"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Seems when saving the model several warnings are appearing: https://github.com/tensorflow/tensorflow/issues/47554\n",
    "hist = model_LSTM.fit(X_train,\n",
    "            y_train,\n",
    "            epochs=100,\n",
    "            verbose=1,\n",
    "            batch_size=256,\n",
    "            validation_data=(X_validation, y_validation),\n",
    "               callbacks=[early_stopping])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vlmZDacGZ3g",
    "outputId": "c0cd3818-81d2-422e-91ee-69fd3b104de5"
   },
   "id": "0vlmZDacGZ3g"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlZrCDyy0yPY",
    "outputId": "26ed957b-5e0c-45d7-8bdf-02b87a19d3f3"
   },
   "outputs": [],
   "source": [
    "def make_preds(model, input_data):\n",
    "  \"\"\"\n",
    "  Uses model to make predictions on input_data.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  model: trained model\n",
    "  input_data: windowed input data (same kind of data model was trained on)\n",
    "\n",
    "  Returns model predictions on input_data.\n",
    "  \"\"\"\n",
    "  forecast = model.predict(input_data,verbose=2)\n",
    "  return tf.squeeze(forecast) # return 1D array of predictions\n",
    "\n",
    "predictions = make_preds(model_LSTM, X_test)"
   ],
   "id": "WlZrCDyy0yPY"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Resultados comparando directamente las salidas\")\n",
    "print(y_test.shape)\n",
    "print(predictions.shape)\n",
    "print('\\033[1m' + \"MSE: \" + str(mean_squared_error(y_test,predictions)) + '\\033[0m')\n",
    "print('\\033[1m' + \"MAE: \" + str(mean_absolute_error(y_test,predictions)) + '\\033[0m')\n",
    "print(np.mean(y_test))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDXB7EByGZ3g",
    "outputId": "f8c11fe3-62b6-43bc-86f5-ec21ba1945bf"
   },
   "id": "fDXB7EByGZ3g"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SPLIT_INTO_TWO_DAYS = True\n",
    "if not MULTI_STEP_FORECAST:\n",
    "  print(\"Resultados poblacionales cada dos horas\")\n",
    "  print('\\033[1m' + \"MSE: \" + str(mean_squared_error(np.sum(y_test,axis=1),np.sum(predictions,axis=1))) + '\\033[0m')\n",
    "  print('\\033[1m' + \"MAE: \" + str(mean_absolute_error(np.sum(y_test,axis=1),np.sum(predictions,axis=1))) + '\\033[0m')\n",
    "  print(\"Ejemplos aleatorios\")\n",
    "  list_of_MAE = [  mean_absolute_error(predictions[i],y_test[i]) for i in range(0,len(y_test)) ]\n",
    "  list_of_values = sorted(list_of_MAE)\n",
    "  mean_value = mean(list_of_MAE)\n",
    "  closest_value = min(list_of_MAE, key=lambda x: abs(x - mean_value))\n",
    "  # Crear un array de Ã­ndices\n",
    "  indices = [list_of_MAE.index(list_of_values[-1]),\n",
    "             list_of_MAE.index(closest_value) ,\n",
    "            list_of_MAE.index(list_of_values[0])]\n",
    "  if COMPUTED_OPTION == 0:\n",
    "    for i in indices:\n",
    "      print(list_of_MAE[i])\n",
    "      plot_predictions_vs_real(predictions[i],y_test[i])\n",
    "  else:\n",
    "    for i in indices:\n",
    "        print(list_of_MAE[i])\n",
    "        END = 24\n",
    "        STARTED_MINUTE = 0\n",
    "        previous = np.ones(shape=(24))\n",
    "        for j in range(0,24):\n",
    "            previous[j] = np.sum(X_test[i,:][60*j:60*(j+1)])\n",
    "        predictions_to_plot = np.ones(shape=(END + HORIZON))\n",
    "        predictions_to_plot[0:END] = previous[:]\n",
    "        predictions_to_plot[END:] = predictions[i,:]\n",
    "        y_test_to_plot = np.ones(shape=(END + HORIZON))\n",
    "        y_test_to_plot[0:END] = previous[:]\n",
    "        y_test_to_plot[END:] = y_test[i,:]\n",
    "        plot_predictions_vs_real(predictions_to_plot,y_test_to_plot)\n",
    "\n",
    "  if SPLIT_INTO_TWO_DAYS:\n",
    "      index = 0\n",
    "      period = X_test[::120,:]\n",
    "      period_results = make_preds(model_LSTM,period)\n",
    "      period_results_to_plot = np.array(period_results).reshape(HORIZON*23)\n",
    "      y_test_to_plot = y_test[::120,:].reshape(HORIZON*23)\n",
    "      plot_predictions_vs_real(predictions=period_results_to_plot,reals=y_test_to_plot)\n",
    "      print('\\033[1m' + \"Predicted: \" + str(np.sum(period_results_to_plot)) + '\\033[0m')\n",
    "      print('\\033[1m' + \"Reals: \" + str(np.sum(y_test_to_plot)) + '\\033[0m')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Eq27HfDsGZ3h",
    "outputId": "78500c44-5ed6-415d-9d2a-42568ed14c0d"
   },
   "id": "Eq27HfDsGZ3h"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if MULTI_STEP_FORECAST:\n",
    "    day_before = np.array(X_test[0:1,:],dtype=np.float32)\n",
    "    predicted_values_day_one = np.ones(shape=(WINDOW_SIZE,1),dtype=np.float32)\n",
    "    for i in range(0,WINDOW_SIZE):\n",
    "        prediction = float(make_preds(model_LSTM, day_before))\n",
    "        day_before[:,0:-1] = day_before[:,1:]\n",
    "        day_before[:,-1] = prediction\n",
    "        predicted_values_day_one[i,0] = prediction\n",
    "\n",
    "    SECOND_DAY = X_test.shape[1]\n",
    "    day_before = np.array(X_test[SECOND_DAY:SECOND_DAY+1,:],dtype=np.float32)\n",
    "    predicted_values_day_two = np.ones(shape=(WINDOW_SIZE,1),dtype=np.float32)\n",
    "    for i in range(0,WINDOW_SIZE):\n",
    "        prediction = float(make_preds(model_LSTM, day_before))\n",
    "        day_before[:,0:-1] = day_before[:,1:]\n",
    "        day_before[:,-1] = prediction\n",
    "        predicted_values_day_two[i,0] = prediction"
   ],
   "metadata": {
    "id": "216DS1g8GZ3h"
   },
   "id": "216DS1g8GZ3h"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_5SRccT8rPJ"
   },
   "outputs": [],
   "source": [
    "if MULTI_STEP_FORECAST:\n",
    "    print(\"Predecidos : \" + str(int(np.sum(predicted_values_day_one[:,0]))))\n",
    "    print(\"Reales : \" + str(int(np.sum(y_test[0:WINDOW_SIZE,0]))))\n",
    "    if COMPUTED_OPTION < 2:\n",
    "        plot_predictions_vs_real(predicted_values_day_one[:,0],y_test[0:WINDOW_SIZE,0])"
   ],
   "id": "i_5SRccT8rPJ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if MULTI_STEP_FORECAST:\n",
    "    print(\"Predecidos : \" + str(int(np.sum(predicted_values_day_two[:,0]))))\n",
    "    print(\"Reales : \" + str(int(np.sum(y_test[SECOND_DAY:,0]))))\n",
    "    if COMPUTED_OPTION < 2:\n",
    "        plot_predictions_vs_real(predicted_values_day_two[:,0],y_test[SECOND_DAY:,0])"
   ],
   "metadata": {
    "id": "RrTRtwdxGZ3h"
   },
   "id": "RrTRtwdxGZ3h"
  },
  {
   "cell_type": "code",
   "source": [
    "SAVE_RESULTS = True\n",
    "if SAVE_RESULTS:\n",
    "  if READ_LOCAL_DATA:\n",
    "    file_path = 'Resources/Resultados/Agregado/'\n",
    "  else:\n",
    "    file_path = \"/content/drive/MyDrive/TFG/Resources/Resultados/Agregado/\"\n",
    "    if LOW_DATA:\n",
    "        file_path += \"LowData/\"\n",
    "\n",
    "    file_path += \"Split\"+str(SPLIT)\n",
    "    documents = ['minuteY','hourY','dayY']\n",
    "    file = file_path+documents[COMPUTED_OPTION]+\"-predictions\"+\".pkl.gz\"\n",
    "    pickle.dump(predictions, gzip.open(file, 'wb'))\n",
    "    file = file_path+documents[COMPUTED_OPTION]+\"-test\"+\".pkl.gz\"\n",
    "    pickle.dump(y_test, gzip.open(file, 'wb'))\n",
    "    file = file_path+documents[COMPUTED_OPTION]+\"-X\"+\".pkl.gz\"\n",
    "    pickle.dump(X_test, gzip.open(file, 'wb'))"
   ],
   "metadata": {
    "id": "hBZgZJrrLadK"
   },
   "id": "hBZgZJrrLadK",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(hist.history[\"loss\"], \"y\", label = \"train_loss\")\n",
    "loss_ax.plot(hist.history[\"val_loss\"], \"r\", label = \"val_loss\")\n",
    "\n",
    "\n",
    "loss_ax.set_ylabel(\"loss\")\n",
    "\n",
    "loss_ax.legend(loc = \"upper left\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
